

ğŸ”¼ PHASE 8 â€” Screen Awareness (READ-ONLY)

Wyzer understands the userâ€™s current visual context without acting.

Add

Active window introspection

Foreground app + title capture

Optional OCR snapshot on demand only

LLM context enrichment:

â€œBased on the current window: Chrome â€“ YouTubeâ€¦â€

Explicitly NOT included

âŒ No clicking
âŒ No typing
âŒ No automation

New components
wyzer/vision/
  â”œâ”€â”€ window_context.py
  â”œâ”€â”€ screen_capture.py
  â””â”€â”€ ocr_engine.py

Orchestrator change

Add read-only context block injected into brain_worker

Hybrid router remains untouched

Why this surpasses the Reddit assistant

Most assistants jump straight to unsafe automation.
Wyzer becomes aware before acting.

Exit criteria

â€œWhat am I looking at?â€ works

OCR only runs when explicitly requested

Zero UI interaction capability



ğŸ”¼ PHASE 9 â€” Declarative Automation (RULE-BASED)

User-defined rules, zero AI guessing.

Add

A rules engine, not an agent.

Example:

When I say "start gaming":
  - set audio â†’ headset
  - launch steam
  - volume â†’ 70%

Storage
wyzer/rules/
  â”œâ”€â”€ rules.json
  â”œâ”€â”€ matcher.py
  â””â”€â”€ executor.py

Critical constraints

Rules are written by user only

LLM can explain rules, never create them

Hybrid router checks rules BEFORE LLM

Exit criteria

Rules trigger deterministically

Rules never self-trigger

Rules can be listed, edited, deleted


ğŸ”¼ PHASE 10 â€” Long-Term Memory Expansion (STILL EXPLICIT)

Memory becomes structured, inspectable, and safe.

Expand memory types

facts

preferences

skills

history markers (optional)

Add commands

â€œWhat do you remember about me?â€

â€œForget everything about Xâ€

â€œExport my memoryâ€

Files touched

memory/memory_manager.py

memory/command_detector.py

data/memory.json

Important

No automatic learning

No memory influences tools or routing

Exit criteria

Memory is human-readable

Memory can be fully disabled

No hallucinated recall



ğŸ”¼ PHASE 11 â€” UI Automation (CONFIRMED + SAFE)

Wyzer can finally act on the screen.

Add

Mouse / keyboard automation

Window targeting

OCR â†’ verify â†’ act loop

Safety rules

Always confirm before acting

Visible preview of target

Global kill switch

Files
wyzer/automation/
  â”œâ”€â”€ input_controller.py
  â”œâ”€â”€ verifier.py
  â””â”€â”€ confirm_gate.py

Exit criteria

Automation never runs silently

Hotword interruption always stops action

ğŸ”¼ PHASE 12 â€” Minimal GUI (OPTIONAL)

Visibility, not dependency.

Add

Tray icon

Mic / hotword toggle

Memory viewer

Skill manager

Log console

Rule

GUI owns zero logic

Core still runs headless.

Exit criteria

GUI optional

Headless mode still primary

GUI crashes do not stop Wyzer

ğŸ”¼ PHASE 13 â€” Opt-In Autonomy

Suggestions, not actions.

Add

â€œWould you like me toâ€¦â€

Contextual suggestions

Explicit approval flow

Hard limits

âŒ No background tasks
âŒ No silent automation
âŒ No self-goals

Exit criteria

Autonomy globally disableable

Full transparency logs